{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "new_data = pd.read_csv(\"providence_merged_new.csv\")\n",
    "newdata = new_data[['speech_act','consistency', 'utterance_type','intonation','syn_level','connective_meaning','annotation','has_negation','modal_bin']]\n",
    "\n",
    "# Exclusive vs Inclusive Data Wrangling\n",
    "exin_newer = newdata.loc[(newdata['connective_meaning'] == 'XOR') | (newdata['connective_meaning'] == 'IOR')]\n",
    "exin_newer_features = pd.get_dummies(exin_newer[['speech_act','consistency', 'utterance_type','intonation','syn_level','has_negation','modal_bin']])\n",
    "exin_newer_labels = np.squeeze(exin_newer[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_trial = [[exin_new_lax_f1_mean,exin_new_lax_f1_perc - exin_new_lax_f1_mean],[exin_new_str_f1_mean,exin_new_str_f1_perc - exin_new_str_f1_mean]]\n",
    "plot_learning_curves(exin_new_sizes,new_trial,'Ex-In F1 Learning Curve with 95 perc','Mean F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Learning Curves\n",
    "exin_newer_sizes, exin_newer_lax_f1_mean, exin_newer_lax_f1_perc = rfc_learning_curve_bin(exin_newer_features,exin_newer_labels,training_sizes,0.05,'f1',True)\n",
    "exin_newer_sizes, exin_newer_str_f1_mean, exin_newer_str_f1_perc = rfc_learning_curve_bin(exin_newer_features,exin_newer_labels,training_sizes,0.2,'f1',True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newer_trial = [[exin_newer_lax_f1_mean,exin_newer_lax_f1_perc - exin_newer_lax_f1_mean],[exin_newer_str_f1_mean,exin_newer_str_f1_perc - exin_newer_str_f1_mean]]\n",
    "plot_learning_curves(exin_newer_sizes,newer_trial,'Ex-In F1 Learning Curve with 95 perc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exin_newer_minds = np.linspace(0.0,0.1,11)[1:]\n",
    "exin_newer_scores, exin_newer_maxes = tradeoff(exin_newer_features,exin_newer_labels,8,exin_newer_minds)\n",
    "\n",
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exin_newer_maxes:\n",
    "    plot_max_estimator(max_tree,exin_newer_features,sorted(list(exin_newer_labels.unique())), 'exin_'+str(0.01*i+0.01))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exin_minds = np.linspace(0.0,0.1,11)[1:]\n",
    "exin_scores, exin_maxes = tradeoff(exin_features,exin_labels,8,exin_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exin_maxes:\n",
    "    plot_max_estimator(max_tree,exin_features,sorted(list(exin_labels.unique())), 'exin_'+str(0.01*i+0.01))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "exin_depths = [t.tree_.max_depth for t in exin_maxes]\n",
    "exin_means = [score.mean() for score in exin_scores]\n",
    "exin_stds = [score.std() for score in exin_scores]\n",
    "plot_tradeoff(exin_minds,exin_depths,exin_means,exin_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclusive vs Inclusive vs AND Data Wrangling\n",
    "exinand = data.loc[(data['connective_meaning'] == 'XOR')|(data['connective_meaning'] == 'IOR')|(data['connective_meaning'] == 'AND')]\n",
    "exinand_features = pd.get_dummies(exinand[['speech_act','consistency', 'utterance_type','intonation','syn_level','annotation']])\n",
    "exinand_labels = np.squeeze(exinand[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Exlcusive vs Inclusive Model\n",
    "training_sizes = np.linspace(1,101,100,dtype=int)\n",
    "exinand_sizes, exinand_mean, exinand_std = rfc_learning_curve(exinand_features,exinand_labels,training_sizes,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Exclusive/Inclusive/AND Model\n",
    "plot_learning_curve(exinand_sizes,exinand_mean,exinand_std,'Exclusive-Inclusive-And Learning Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exinand_minds = np.linspace(0.0,0.05,11)[1:]\n",
    "exinand_scores, exinand_maxes = tradeoff(exinand_features,exinand_labels,8,exinand_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exinand_maxes:\n",
    "    plot_max_estimator(max_tree,exinand_features,sorted(list(exinand_labels.unique())), 'exinand_'+str(0.005*i+0.005))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "exinand_depths = [t.tree_.max_depth for t in exinand_maxes]\n",
    "exinand_means = [score.mean() for score in exinand_scores]\n",
    "exinand_stds = [score.std() for score in exinand_scores]\n",
    "plot_tradeoff(exinand_minds,exinand_depths,exinand_means,exinand_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whole Data Wrangling\n",
    "whole = data.loc[data['connective_meaning'] != 'XNOR']\n",
    "whole_features = pd.get_dummies(whole[['consistency', 'intonation','annotation','speech_act','syn_level','utterance_type']])\n",
    "whole_labels = np.squeeze(whole[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Whole Model\n",
    "training_sizes = np.linspace(1,101,100,dtype=int)\n",
    "whole_sizes, whole_mean, whole_std = rfc_learning_curve(whole_features,whole_labels,training_sizes,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Whole Model\n",
    "plot_learning_curve(whole_sizes,whole_mean,whole_std,'Whole Model Learning Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "whole_minds = np.linspace(0.0,0.05,11)[1:]\n",
    "whole_scores, whole_maxes = tradeoff(whole_features,whole_labels,8,whole_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in whole_maxes:\n",
    "    plot_max_estimator(max_tree,whole_features,sorted(list(whole_labels.unique())), 'whole_'+str(0.005*i+0.005))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "whole_depths = [t.tree_.max_depth for t in whole_maxes]\n",
    "whole_means = [score.mean() for score in whole_scores]\n",
    "whole_stds = [score.std() for score in whole_scores]\n",
    "plot_tradeoff(whole_minds,whole_depths,whole_means,whole_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(minds,exin_stds,label='Ex-In')\n",
    "plt.plot(minds,exinand_stds,label='Ex-In-And')\n",
    "plt.plot(minds,whole_stds,label='All')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ROC for ExIn\n",
    "le = LabelEncoder()\n",
    "le.fit(exin_labels)\n",
    "binarized = le.transform(exin_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(exin_features, binarized, test_size=0.8)\n",
    "clf = rfc(n_estimators=20,max_depth=8,max_features=None,min_impurity_decrease=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,lw=2)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve with AUC = ' + \"%.2f\" % roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ROC for ExIn\n",
    "le = LabelEncoder()\n",
    "le.fit(exin_labels)\n",
    "binarized = le.transform(exin_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(exin_features, binarized, test_size=0.8)\n",
    "clf = rfc(n_estimators=20,max_depth=8,max_features=None,min_impurity_decrease=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,lw=2)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve with AUC = ' + \"%.2f\" % roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclusive vs Inclusive Data Wrangling\n",
    "exin = data.loc[(data['connective_meaning'] == 'XOR') | (data['connective_meaning'] == 'IOR')]\n",
    "exin_features = pd.get_dummies(exin[['speech_act','consistency', 'utterance_type','intonation','syn_level']])\n",
    "exin_labels = np.squeeze(exin[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Exlcusive vs Inclusive Model\n",
    "training_sizes = np.linspace(1,151,150,dtype=int)\n",
    "exin_sizes, exin_lax_acc_mean, exin_lax_acc_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05)\n",
    "exin_sizes, exin_str_acc_mean, exin_str_acc_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exin_sizes, exin_lax_f1_mean, exin_lax_f1_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05,'f1',False)\n",
    "exin_sizes, exin_str_f1_mean, exin_str_f1_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2,'f1',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Exclusive/Inclusive Model\n",
    "acc_mean_std = [[exin_lax_acc_mean,exin_lax_acc_std],[exin_str_acc_mean,exin_str_acc_std]]\n",
    "plot_learning_curves(exin_sizes,acc_mean_std,'Exclusive-Inclusive Accuracy Learning Curve','Mean Accuracy')\n",
    "f1_mean_std = [[exin_lax_f1_mean,exin_lax_f1_std],[exin_str_f1_mean,exin_str_f1_std]]\n",
    "plot_learning_curves(exin_sizes,f1_mean_std,'Exclusive-Inclusive F1 Learning Curve','Mean F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percentile Trial\n",
    "exin_sizes, exin_lax_f1_mean, exin_lax_f1_perc= rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05,'f1',True)\n",
    "exin_sizes, exin_str_f1_mean, exin_str_f1_perc= rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2,'f1',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting 95 percentiles\n",
    "perc_trial = [[exin_lax_f1_mean,exin_lax_f1_perc - exin_lax_f1_mean],[exin_str_f1_mean,exin_str_f1_perc - exin_str_f1_mean]]\n",
    "plot_learning_curves(exin_sizes,perc_trial,'Exclusive-Inclusive F1 Learning Curve with 95 perc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "new_data = pd.read_csv(\"providence_merged_new.csv\")\n",
    "newdata = new_data[['speech_act','consistency', 'utterance_type','intonation','syn_level','connective_meaning','annotation','has_negation','modal_bin']]\n",
    "\n",
    "# Exclusive vs Inclusive Data Wrangling\n",
    "exin_newer = newdata.loc[(newdata['connective_meaning'] == 'XOR') | (newdata['connective_meaning'] == 'IOR')]\n",
    "exin_newer_features = pd.get_dummies(exin_newer[['speech_act','consistency', 'utterance_type','intonation','syn_level','has_negation','modal_bin']])\n",
    "exin_newer_labels = np.squeeze(exin_newer[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_trial = [[exin_new_lax_f1_mean,exin_new_lax_f1_perc - exin_new_lax_f1_mean],[exin_new_str_f1_mean,exin_new_str_f1_perc - exin_new_str_f1_mean]]\n",
    "plot_learning_curves(exin_new_sizes,new_trial,'Ex-In F1 Learning Curve with 95 perc','Mean F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Learning Curves\n",
    "exin_newer_sizes, exin_newer_lax_f1_mean, exin_newer_lax_f1_perc = rfc_learning_curve_bin(exin_newer_features,exin_newer_labels,training_sizes,0.05,'f1',True)\n",
    "exin_newer_sizes, exin_newer_str_f1_mean, exin_newer_str_f1_perc = rfc_learning_curve_bin(exin_newer_features,exin_newer_labels,training_sizes,0.2,'f1',True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newer_trial = [[exin_newer_lax_f1_mean,exin_newer_lax_f1_perc - exin_newer_lax_f1_mean],[exin_newer_str_f1_mean,exin_newer_str_f1_perc - exin_newer_str_f1_mean]]\n",
    "plot_learning_curves(exin_newer_sizes,newer_trial,'Ex-In F1 Learning Curve with 95 perc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exin_newer_minds = np.linspace(0.0,0.1,11)[1:]\n",
    "exin_newer_scores, exin_newer_maxes = tradeoff(exin_newer_features,exin_newer_labels,8,exin_newer_minds)\n",
    "\n",
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exin_newer_maxes:\n",
    "    plot_max_estimator(max_tree,exin_newer_features,sorted(list(exin_newer_labels.unique())), 'exin_'+str(0.01*i+0.01))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exin_minds = np.linspace(0.0,0.1,11)[1:]\n",
    "exin_scores, exin_maxes = tradeoff(exin_features,exin_labels,8,exin_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exin_maxes:\n",
    "    plot_max_estimator(max_tree,exin_features,sorted(list(exin_labels.unique())), 'exin_'+str(0.01*i+0.01))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "exin_depths = [t.tree_.max_depth for t in exin_maxes]\n",
    "exin_means = [score.mean() for score in exin_scores]\n",
    "exin_stds = [score.std() for score in exin_scores]\n",
    "plot_tradeoff(exin_minds,exin_depths,exin_means,exin_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclusive vs Inclusive vs AND Data Wrangling\n",
    "exinand = data.loc[(data['connective_meaning'] == 'XOR')|(data['connective_meaning'] == 'IOR')|(data['connective_meaning'] == 'AND')]\n",
    "exinand_features = pd.get_dummies(exinand[['speech_act','consistency', 'utterance_type','intonation','syn_level','annotation']])\n",
    "exinand_labels = np.squeeze(exinand[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Exlcusive vs Inclusive Model\n",
    "training_sizes = np.linspace(1,101,100,dtype=int)\n",
    "exinand_sizes, exinand_mean, exinand_std = rfc_learning_curve(exinand_features,exinand_labels,training_sizes,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Exclusive/Inclusive/AND Model\n",
    "plot_learning_curve(exinand_sizes,exinand_mean,exinand_std,'Exclusive-Inclusive-And Learning Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "exinand_minds = np.linspace(0.0,0.05,11)[1:]\n",
    "exinand_scores, exinand_maxes = tradeoff(exinand_features,exinand_labels,8,exinand_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in exinand_maxes:\n",
    "    plot_max_estimator(max_tree,exinand_features,sorted(list(exinand_labels.unique())), 'exinand_'+str(0.005*i+0.005))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "exinand_depths = [t.tree_.max_depth for t in exinand_maxes]\n",
    "exinand_means = [score.mean() for score in exinand_scores]\n",
    "exinand_stds = [score.std() for score in exinand_scores]\n",
    "plot_tradeoff(exinand_minds,exinand_depths,exinand_means,exinand_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Whole Data Wrangling\n",
    "whole = data.loc[data['connective_meaning'] != 'XNOR']\n",
    "whole_features = pd.get_dummies(whole[['consistency', 'intonation','annotation','speech_act','syn_level','utterance_type']])\n",
    "whole_labels = np.squeeze(whole[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Whole Model\n",
    "training_sizes = np.linspace(1,101,100,dtype=int)\n",
    "whole_sizes, whole_mean, whole_std = rfc_learning_curve(whole_features,whole_labels,training_sizes,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Whole Model\n",
    "plot_learning_curve(whole_sizes,whole_mean,whole_std,'Whole Model Learning Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count Error Accuracy Trade Off\n",
    "whole_minds = np.linspace(0.0,0.05,11)[1:]\n",
    "whole_scores, whole_maxes = tradeoff(whole_features,whole_labels,8,whole_minds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Observe Effect of min impurity difference on feature use\n",
    "i=0\n",
    "for max_tree in whole_maxes:\n",
    "    plot_max_estimator(max_tree,whole_features,sorted(list(whole_labels.unique())), 'whole_'+str(0.005*i+0.005))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the Min Impurity Difference Effect\n",
    "whole_depths = [t.tree_.max_depth for t in whole_maxes]\n",
    "whole_means = [score.mean() for score in whole_scores]\n",
    "whole_stds = [score.std() for score in whole_scores]\n",
    "plot_tradeoff(whole_minds,whole_depths,whole_means,whole_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(minds,exin_stds,label='Ex-In')\n",
    "plt.plot(minds,exinand_stds,label='Ex-In-And')\n",
    "plt.plot(minds,whole_stds,label='All')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ROC for ExIn\n",
    "le = LabelEncoder()\n",
    "le.fit(exin_labels)\n",
    "binarized = le.transform(exin_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(exin_features, binarized, test_size=0.8)\n",
    "clf = rfc(n_estimators=20,max_depth=8,max_features=None,min_impurity_decrease=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,lw=2)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve with AUC = ' + \"%.2f\" % roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ROC for ExIn\n",
    "le = LabelEncoder()\n",
    "le.fit(exin_labels)\n",
    "binarized = le.transform(exin_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(exin_features, binarized, test_size=0.8)\n",
    "clf = rfc(n_estimators=20,max_depth=8,max_features=None,min_impurity_decrease=0.01)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,lw=2)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve with AUC = ' + \"%.2f\" % roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exclusive vs Inclusive Data Wrangling\n",
    "exin = data.loc[(data['connective_meaning'] == 'XOR') | (data['connective_meaning'] == 'IOR')]\n",
    "exin_features = pd.get_dummies(exin[['speech_act','consistency', 'utterance_type','intonation','syn_level']])\n",
    "exin_labels = np.squeeze(exin[['connective_meaning']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Exlcusive vs Inclusive Model\n",
    "training_sizes = np.linspace(1,151,150,dtype=int)\n",
    "exin_sizes, exin_lax_acc_mean, exin_lax_acc_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05)\n",
    "exin_sizes, exin_str_acc_mean, exin_str_acc_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exin_sizes, exin_lax_f1_mean, exin_lax_f1_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05,'f1',False)\n",
    "exin_sizes, exin_str_f1_mean, exin_str_f1_std = rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2,'f1',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Learning Curve for Exclusive/Inclusive Model\n",
    "acc_mean_std = [[exin_lax_acc_mean,exin_lax_acc_std],[exin_str_acc_mean,exin_str_acc_std]]\n",
    "plot_learning_curves(exin_sizes,acc_mean_std,'Exclusive-Inclusive Accuracy Learning Curve','Mean Accuracy')\n",
    "f1_mean_std = [[exin_lax_f1_mean,exin_lax_f1_std],[exin_str_f1_mean,exin_str_f1_std]]\n",
    "plot_learning_curves(exin_sizes,f1_mean_std,'Exclusive-Inclusive F1 Learning Curve','Mean F1 Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Percentile Trial\n",
    "exin_sizes, exin_lax_f1_mean, exin_lax_f1_perc= rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.05,'f1',True)\n",
    "exin_sizes, exin_str_f1_mean, exin_str_f1_perc= rfc_learning_curve_bin(exin_features,exin_labels,training_sizes,0.2,'f1',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting 95 percentiles\n",
    "perc_trial = [[exin_lax_f1_mean,exin_lax_f1_perc - exin_lax_f1_mean],[exin_str_f1_mean,exin_str_f1_perc - exin_str_f1_mean]]\n",
    "plot_learning_curves(exin_sizes,perc_trial,'Exclusive-Inclusive F1 Learning Curve with 95 perc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting ROC for ExIn\n",
    "le = LabelEncoder()\n",
    "le.fit(exin_new_labels)\n",
    "binarized = le.transform(exin_new_labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(exin_new_features, binarized, test_size=0.8)\n",
    "clf = rfc(n_estimators=20,max_depth=8,max_features=None,min_impurity_decrease=0.05)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr,tpr,lw=2)\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve with AUC = ' + \"%.2f\" % roc_auc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WITH IN AS TARGET\n",
    "exin_new_sizes, exin_new_lax_f1_in = fh.rfc_learning_curve_bin(exin_new_features,exin_new_labels,training_sizes,0.05,'f1',True,False,True)\n",
    "exin_new_sizes, exin_new_str_f1_in = fh.rfc_learning_curve_bin(exin_new_features,exin_new_labels,training_sizes,0.2,'f1',True,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# WITH EX AS TARGET\n",
    "exin_new_sizes, exin_new_lax_f1_ex = fh.rfc_learning_curve_bin(exin_new_features,exin_new_labels,training_sizes,0.05,'f1',True,True,True)\n",
    "exin_new_sizes, exin_new_str_f1_ex = fh.rfc_learning_curve_bin(exin_new_features,exin_new_labels,training_sizes,0.2,'f1',True,True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print stats.shapiro(exin_new_str_f1_ex[0])\n",
    "print stats.shapiro(exin_new_lax_f1_ex[0])\n",
    "plt.hist(exin_new_lax_f1_ex[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print stats.ttest_ind(exin_new_lax_f1_ex[0],exin_new_str_f1_ex[0])\n",
    "print stats.ttest_ind(exin_new_lax_f1_in[0],exin_new_str_f1_in[0])\n",
    "means = [np.mean(exin_new_lax_f1_ex,axis=1)[0], np.mean(exin_new_str_f1_ex,axis=1)[0], np.mean(exin_new_lax_f1_in,axis=1)[0], np.mean(exin_new_str_f1_in,axis=1)[0]]\n",
    "percs = [abs(np.percentile(exin_new_lax_f1_ex,95,axis=1) - np.mean(exin_new_lax_f1_ex,axis=1))[0], abs(np.percentile(exin_new_str_f1_ex,95,axis=1) - np.mean(exin_new_str_f1_ex,axis=1))[0], abs(np.percentile(exin_new_lax_f1_in,95,axis=1) - np.mean(exin_new_lax_f1_in,axis=1))[0],\n",
    "         abs(np.percentile(exin_new_str_f1_in,95,axis=1) - np.mean(exin_new_str_f1_in,axis=1))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.arange(4)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(ind[:2],means[:2],yerr=percs[:2],color=['#00BFC4','#F8766D'],width=0.5)\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.title('EX F1 Score with 95% Interval (p-value = 0)')\n",
    "plt.xticks(ind[:2], ('EX Tree', 'EX Baseline'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(ind[2:],means[2:],yerr=percs[2:],color=['#00BFC4','#F8766D'],width=0.5)\n",
    "plt.ylabel('F1 Scores')\n",
    "plt.title('IN F1 Score with 95% Interval (p-value = 0)')\n",
    "plt.xticks(ind[2:], ('IN Lax', 'IN Baseline'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
